{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mercedes Benz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_file = 'training/train.csv'\n",
    "test_file = 'training/test.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_file)\n",
    "test_df = pd.read_csv(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>y</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>130.81</td>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>at</td>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "      <td>u</td>\n",
       "      <td>j</td>\n",
       "      <td>o</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>88.53</td>\n",
       "      <td>k</td>\n",
       "      <td>t</td>\n",
       "      <td>av</td>\n",
       "      <td>e</td>\n",
       "      <td>d</td>\n",
       "      <td>y</td>\n",
       "      <td>l</td>\n",
       "      <td>o</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>76.26</td>\n",
       "      <td>az</td>\n",
       "      <td>w</td>\n",
       "      <td>n</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>x</td>\n",
       "      <td>j</td>\n",
       "      <td>x</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>80.62</td>\n",
       "      <td>az</td>\n",
       "      <td>t</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>x</td>\n",
       "      <td>l</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>78.02</td>\n",
       "      <td>az</td>\n",
       "      <td>v</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>h</td>\n",
       "      <td>d</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 378 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID       y  X0 X1  X2 X3 X4 X5 X6 X8  ...   X375  X376  X377  X378  X379  \\\n",
       "0   0  130.81   k  v  at  a  d  u  j  o  ...      0     0     1     0     0   \n",
       "1   6   88.53   k  t  av  e  d  y  l  o  ...      1     0     0     0     0   \n",
       "2   7   76.26  az  w   n  c  d  x  j  x  ...      0     0     0     0     0   \n",
       "3   9   80.62  az  t   n  f  d  x  l  e  ...      0     0     0     0     0   \n",
       "4  13   78.02  az  v   n  f  d  h  d  n  ...      0     0     0     0     0   \n",
       "\n",
       "   X380  X382  X383  X384  X385  \n",
       "0     0     0     0     0     0  \n",
       "1     0     0     0     0     0  \n",
       "2     0     1     0     0     0  \n",
       "3     0     0     0     0     0  \n",
       "4     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 378 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>az</td>\n",
       "      <td>v</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>w</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>t</td>\n",
       "      <td>b</td>\n",
       "      <td>ai</td>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "      <td>b</td>\n",
       "      <td>g</td>\n",
       "      <td>y</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>az</td>\n",
       "      <td>v</td>\n",
       "      <td>as</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "      <td>j</td>\n",
       "      <td>j</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>az</td>\n",
       "      <td>l</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>z</td>\n",
       "      <td>l</td>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>w</td>\n",
       "      <td>s</td>\n",
       "      <td>as</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>y</td>\n",
       "      <td>i</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 377 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  X0 X1  X2 X3 X4 X5 X6 X8  X10  ...   X375  X376  X377  X378  X379  \\\n",
       "0   1  az  v   n  f  d  t  a  w    0  ...      0     0     0     1     0   \n",
       "1   2   t  b  ai  a  d  b  g  y    0  ...      0     0     1     0     0   \n",
       "2   3  az  v  as  f  d  a  j  j    0  ...      0     0     0     1     0   \n",
       "3   4  az  l   n  f  d  z  l  n    0  ...      0     0     0     1     0   \n",
       "4   5   w  s  as  c  d  y  i  m    0  ...      1     0     0     0     0   \n",
       "\n",
       "   X380  X382  X383  X384  X385  \n",
       "0     0     0     0     0     0  \n",
       "1     0     0     0     0     0  \n",
       "2     0     0     0     0     0  \n",
       "3     0     0     0     0     0  \n",
       "4     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 377 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "# To evaluate models using cross-validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "# To perform data preparation in order to improve skill with Keras models\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Ensemble\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Feature Selection\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for c in train_df.columns:\n",
    "    if train_df[c].dtype == 'object':\n",
    "        lbl = LabelEncoder() \n",
    "        lbl.fit(list(train_df[c].values)) \n",
    "        train_df[c] = lbl.transform(list(train_df[c].values))\n",
    "        \n",
    "for c in test_df.columns:\n",
    "    if test_df[c].dtype == 'object':\n",
    "        lbl = LabelEncoder() \n",
    "        lbl.fit(list(test_df[c].values)) \n",
    "        test_df[c] = lbl.transform(list(test_df[c].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "4209/4209 [==============================] - 2s - loss: 737.9321     \n",
      "Epoch 2/500\n",
      "4209/4209 [==============================] - 2s - loss: 87.9134     \n",
      "Epoch 3/500\n",
      "4209/4209 [==============================] - 2s - loss: 83.6398     \n",
      "Epoch 4/500\n",
      "4209/4209 [==============================] - 2s - loss: 81.7848     \n",
      "Epoch 5/500\n",
      "4209/4209 [==============================] - 2s - loss: 82.0808     \n",
      "Epoch 6/500\n",
      "4209/4209 [==============================] - 2s - loss: 79.0246     \n",
      "Epoch 7/500\n",
      "4209/4209 [==============================] - 2s - loss: 78.0185     \n",
      "Epoch 8/500\n",
      "4209/4209 [==============================] - 2s - loss: 78.2162     \n",
      "Epoch 9/500\n",
      "4209/4209 [==============================] - 2s - loss: 77.2380     \n",
      "Epoch 10/500\n",
      "4209/4209 [==============================] - 2s - loss: 74.2853     \n",
      "Epoch 11/500\n",
      "4209/4209 [==============================] - 2s - loss: 74.9774     \n",
      "Epoch 12/500\n",
      "4209/4209 [==============================] - 2s - loss: 76.1932     \n",
      "Epoch 13/500\n",
      "4209/4209 [==============================] - 2s - loss: 73.3310     \n",
      "Epoch 14/500\n",
      "4209/4209 [==============================] - 2s - loss: 73.5497     \n",
      "Epoch 15/500\n",
      "4209/4209 [==============================] - 2s - loss: 73.5941     \n",
      "Epoch 16/500\n",
      "4209/4209 [==============================] - 2s - loss: 73.3736     \n",
      "Epoch 17/500\n",
      "4209/4209 [==============================] - 2s - loss: 74.8849     \n",
      "Epoch 18/500\n",
      "4209/4209 [==============================] - 2s - loss: 73.3369     \n",
      "Epoch 19/500\n",
      "4209/4209 [==============================] - 2s - loss: 71.4631     \n",
      "Epoch 20/500\n",
      "4209/4209 [==============================] - 2s - loss: 71.8186     \n",
      "Epoch 21/500\n",
      "4209/4209 [==============================] - 2s - loss: 70.3496     \n",
      "Epoch 22/500\n",
      "4209/4209 [==============================] - 2s - loss: 72.8145     \n",
      "Epoch 23/500\n",
      "4209/4209 [==============================] - 2s - loss: 71.0420     \n",
      "Epoch 24/500\n",
      "4209/4209 [==============================] - 2s - loss: 71.1872     \n",
      "Epoch 25/500\n",
      "4209/4209 [==============================] - 2s - loss: 69.8377     \n",
      "Epoch 26/500\n",
      "4209/4209 [==============================] - 2s - loss: 69.7383     \n",
      "Epoch 27/500\n",
      "4209/4209 [==============================] - 2s - loss: 69.1810     \n",
      "Epoch 28/500\n",
      "4209/4209 [==============================] - 2s - loss: 68.4763     \n",
      "Epoch 29/500\n",
      "4209/4209 [==============================] - 2s - loss: 66.6372     \n",
      "Epoch 30/500\n",
      "4209/4209 [==============================] - 2s - loss: 67.3854     \n",
      "Epoch 31/500\n",
      "4209/4209 [==============================] - 2s - loss: 68.1023     \n",
      "Epoch 32/500\n",
      "4209/4209 [==============================] - 2s - loss: 67.6675     \n",
      "Epoch 33/500\n",
      "4209/4209 [==============================] - 2s - loss: 65.5150     \n",
      "Epoch 34/500\n",
      "4209/4209 [==============================] - 2s - loss: 66.6838     \n",
      "Epoch 35/500\n",
      "4209/4209 [==============================] - 2s - loss: 65.2019     \n",
      "Epoch 36/500\n",
      "4209/4209 [==============================] - 2s - loss: 65.0800     \n",
      "Epoch 37/500\n",
      "4209/4209 [==============================] - 2s - loss: 63.7824     \n",
      "Epoch 38/500\n",
      "4209/4209 [==============================] - 2s - loss: 63.4965     \n",
      "Epoch 39/500\n",
      "4209/4209 [==============================] - 2s - loss: 64.7234     \n",
      "Epoch 40/500\n",
      "4209/4209 [==============================] - 2s - loss: 63.3443     \n",
      "Epoch 41/500\n",
      "4209/4209 [==============================] - 2s - loss: 62.7873     \n",
      "Epoch 42/500\n",
      "4209/4209 [==============================] - 2s - loss: 61.8831     \n",
      "Epoch 43/500\n",
      "4209/4209 [==============================] - 2s - loss: 62.0898     \n",
      "Epoch 44/500\n",
      "4209/4209 [==============================] - 2s - loss: 59.0107     \n",
      "Epoch 45/500\n",
      "4209/4209 [==============================] - 2s - loss: 60.4223     \n",
      "Epoch 46/500\n",
      "4209/4209 [==============================] - 2s - loss: 59.6084     \n",
      "Epoch 47/500\n",
      "4209/4209 [==============================] - 2s - loss: 59.3942     \n",
      "Epoch 48/500\n",
      "4209/4209 [==============================] - 2s - loss: 58.8464     \n",
      "Epoch 49/500\n",
      "4209/4209 [==============================] - 2s - loss: 59.7592     \n",
      "Epoch 50/500\n",
      "4209/4209 [==============================] - 2s - loss: 59.1722     \n",
      "Epoch 51/500\n",
      "4209/4209 [==============================] - 2s - loss: 56.9538     \n",
      "Epoch 52/500\n",
      "4209/4209 [==============================] - 2s - loss: 56.5771     \n",
      "Epoch 53/500\n",
      "4209/4209 [==============================] - 2s - loss: 56.9562     \n",
      "Epoch 54/500\n",
      "4209/4209 [==============================] - 2s - loss: 58.0571     \n",
      "Epoch 55/500\n",
      "4209/4209 [==============================] - 2s - loss: 55.1033     \n",
      "Epoch 56/500\n",
      "4209/4209 [==============================] - 2s - loss: 54.3607     \n",
      "Epoch 57/500\n",
      "4209/4209 [==============================] - 2s - loss: 53.8919     \n",
      "Epoch 58/500\n",
      "4209/4209 [==============================] - 2s - loss: 54.6216     \n",
      "Epoch 59/500\n",
      "4209/4209 [==============================] - 2s - loss: 53.9509     \n",
      "Epoch 60/500\n",
      "4209/4209 [==============================] - 2s - loss: 52.6935     \n",
      "Epoch 61/500\n",
      "4209/4209 [==============================] - 2s - loss: 52.4317     \n",
      "Epoch 62/500\n",
      "4209/4209 [==============================] - 2s - loss: 51.8465     \n",
      "Epoch 63/500\n",
      "4209/4209 [==============================] - 2s - loss: 51.1352     \n",
      "Epoch 64/500\n",
      "4209/4209 [==============================] - 2s - loss: 51.7610     \n",
      "Epoch 65/500\n",
      "4209/4209 [==============================] - 2s - loss: 50.0212     \n",
      "Epoch 66/500\n",
      "4209/4209 [==============================] - 2s - loss: 49.6319     \n",
      "Epoch 67/500\n",
      "4209/4209 [==============================] - 2s - loss: 48.6166     \n",
      "Epoch 68/500\n",
      "4209/4209 [==============================] - 2s - loss: 50.7437     \n",
      "Epoch 69/500\n",
      "4209/4209 [==============================] - 2s - loss: 47.6200     \n",
      "Epoch 70/500\n",
      "4209/4209 [==============================] - 2s - loss: 48.1006     \n",
      "Epoch 71/500\n",
      "4209/4209 [==============================] - 2s - loss: 46.0820     \n",
      "Epoch 72/500\n",
      "4209/4209 [==============================] - 2s - loss: 48.2909     \n",
      "Epoch 73/500\n",
      "4209/4209 [==============================] - 2s - loss: 46.4332     \n",
      "Epoch 74/500\n",
      "4209/4209 [==============================] - 2s - loss: 45.8276     \n",
      "Epoch 75/500\n",
      "4209/4209 [==============================] - 2s - loss: 45.1397     \n",
      "Epoch 76/500\n",
      "4209/4209 [==============================] - 2s - loss: 46.3342     \n",
      "Epoch 77/500\n",
      "4209/4209 [==============================] - 2s - loss: 44.3178     \n",
      "Epoch 78/500\n",
      "4209/4209 [==============================] - 2s - loss: 44.6936     \n",
      "Epoch 79/500\n",
      "4209/4209 [==============================] - 2s - loss: 44.7643     \n",
      "Epoch 80/500\n",
      "4209/4209 [==============================] - 2s - loss: 42.4739     \n",
      "Epoch 81/500\n",
      "4209/4209 [==============================] - 2s - loss: 43.2054     \n",
      "Epoch 82/500\n",
      "4209/4209 [==============================] - 2s - loss: 43.0143     \n",
      "Epoch 83/500\n",
      "4209/4209 [==============================] - 2s - loss: 41.4606     \n",
      "Epoch 84/500\n",
      "4209/4209 [==============================] - 2s - loss: 42.0576     \n",
      "Epoch 85/500\n",
      "4209/4209 [==============================] - 2s - loss: 40.8239     \n",
      "Epoch 86/500\n",
      "4209/4209 [==============================] - 2s - loss: 41.8239     \n",
      "Epoch 87/500\n",
      "4209/4209 [==============================] - 2s - loss: 39.9029     \n",
      "Epoch 88/500\n",
      "4209/4209 [==============================] - 2s - loss: 40.0447     \n",
      "Epoch 89/500\n",
      "4209/4209 [==============================] - 2s - loss: 38.5782     \n",
      "Epoch 90/500\n",
      "4209/4209 [==============================] - 2s - loss: 38.6720     \n",
      "Epoch 91/500\n",
      "4209/4209 [==============================] - 2s - loss: 38.5905     \n",
      "Epoch 92/500\n",
      "4209/4209 [==============================] - 2s - loss: 38.0424     \n",
      "Epoch 93/500\n",
      "4209/4209 [==============================] - 2s - loss: 38.0344     \n",
      "Epoch 94/500\n",
      "4209/4209 [==============================] - 2s - loss: 39.7297     \n",
      "Epoch 95/500\n",
      "4209/4209 [==============================] - 2s - loss: 37.1123     \n",
      "Epoch 96/500\n",
      "4209/4209 [==============================] - 2s - loss: 36.6222     \n",
      "Epoch 97/500\n",
      "4209/4209 [==============================] - 2s - loss: 35.9651     \n",
      "Epoch 98/500\n",
      "4209/4209 [==============================] - 2s - loss: 37.2605     \n",
      "Epoch 99/500\n",
      "4209/4209 [==============================] - 2s - loss: 35.3508     \n",
      "Epoch 100/500\n",
      "4209/4209 [==============================] - 2s - loss: 36.3562     \n",
      "Epoch 101/500\n",
      "4209/4209 [==============================] - 2s - loss: 36.3354     \n",
      "Epoch 102/500\n",
      "4209/4209 [==============================] - 2s - loss: 34.1942     \n",
      "Epoch 103/500\n",
      "4209/4209 [==============================] - 2s - loss: 35.1306     \n",
      "Epoch 104/500\n",
      "4209/4209 [==============================] - 2s - loss: 34.6209     \n",
      "Epoch 105/500\n",
      "4209/4209 [==============================] - 2s - loss: 33.8573     \n",
      "Epoch 106/500\n",
      "4209/4209 [==============================] - 2s - loss: 34.6505     \n",
      "Epoch 107/500\n",
      "4209/4209 [==============================] - 2s - loss: 35.3724     \n",
      "Epoch 108/500\n",
      "4209/4209 [==============================] - 2s - loss: 33.6650     \n",
      "Epoch 109/500\n",
      "4209/4209 [==============================] - 2s - loss: 33.3702     \n",
      "Epoch 110/500\n",
      "4209/4209 [==============================] - 2s - loss: 34.9734     \n",
      "Epoch 111/500\n",
      "4209/4209 [==============================] - 2s - loss: 33.0473     \n",
      "Epoch 112/500\n",
      "4209/4209 [==============================] - 2s - loss: 33.1700     \n",
      "Epoch 113/500\n",
      "4209/4209 [==============================] - 2s - loss: 32.2097     \n",
      "Epoch 114/500\n",
      "4209/4209 [==============================] - 2s - loss: 31.6438     \n",
      "Epoch 115/500\n",
      "4209/4209 [==============================] - 2s - loss: 33.0634     \n",
      "Epoch 116/500\n",
      "4209/4209 [==============================] - 2s - loss: 31.9602     \n",
      "Epoch 117/500\n",
      "4209/4209 [==============================] - 2s - loss: 32.3754     \n",
      "Epoch 118/500\n",
      "4209/4209 [==============================] - 2s - loss: 33.0513     \n",
      "Epoch 119/500\n",
      "4209/4209 [==============================] - 2s - loss: 30.7844     \n",
      "Epoch 120/500\n",
      "1335/4209 [========>.....................] - ETA: 1s - loss: 32.8708"
     ]
    }
   ],
   "source": [
    "# define base model\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    # Topology 13 inputs -> [13 -> 6] -> 1 output\n",
    "    model = Sequential()\n",
    "    model.add(Dense(376, input_dim=376, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(36, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(6, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "id_test = test_df['ID']\n",
    "test_noID = test_df.drop(\"ID\", axis=1).copy()\n",
    "# no DataFrame\n",
    "test_reduced = model.transform(test_noID)\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "estimator = KerasRegressor(build_fn=baseline_model, epochs=500, batch_size=5, verbose=1)\n",
    "\n",
    "# Numpy representation of NDFrame\n",
    "dataset = train_df.values\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,2:378]\n",
    "Y = dataset[:,1]\n",
    "\n",
    "datasetTest = test_noID.values\n",
    "# split into input (X) and output (Y) variables\n",
    "X_test = datasetTest[:,0:376]\n",
    "\n",
    "estimator.fit(X,Y)\n",
    "res = clf.predict(X_test)\n",
    "\n",
    "output = pd.DataFrame({'id': id_test, 'y': res})\n",
    "output.to_csv('preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_df = pd.read_csv('preds.csv')\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
